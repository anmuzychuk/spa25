# End-to-end ETL pipeline

This project implements a simple ETL pipeline using functionality provided by Databricks. The primary module used is the Pipeline, which enables step-by-step operations on a Delta Lake table by executing code according to an automatically generated dependency graph. This approach allows for easier modification and scaling of existing systems compared to traditional methods, such as creating sequences of jobs and manually managing dependencies and execution order.

## ğŸ“ Project Structure

```
end-to-end-etl-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ presentation/
â”‚   â””â”€â”€ slides.pdf
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ sample_data.csv
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â””â”€â”€ documentation/
    â””â”€â”€ report.md
```

## ğŸ“§ Contact
- **Author**: Artur Pelcharskyi
- **Project Repository**: https://github.com/PelArtur/BigData-SelfPickedAssignment
- **Presentation Date**: 03-12-2025
- **Course**: Big data processing technologies

